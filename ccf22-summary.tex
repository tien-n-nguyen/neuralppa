\documentclass[11pt]{article}

\usepackage{graphicx,times}
\usepackage{wrapfig}
\usepackage{amsmath,epsfig}
\usepackage{setspace,array}
\usepackage{cite}
\usepackage{xspace}
\usepackage{enumitem}

\usepackage{sectsty}
\sectionfont{\large}
\subsectionfont{\normalsize}
\subsubsectionfont{\normalsize}

\usepackage[compact]{titlesec}

\renewcommand{\theequation}{\thesection.\arabic{equation}}
\renewcommand{\baselinestretch}{1.0}

\newtheorem{Definition}{Definition}
\newtheorem{Claim}{Claim}
\newtheorem{Lemma}{Lemma}
\newtheorem{Theorem}{Theorem}
\newtheorem{Property}{Property}

\newcommand{\revise} {\bf}

\newcommand{\code}[1]{{\small\texttt{#1}}}
\newcommand{\op}{\tau}
\newcommand{\refac}{\rho}
\newcommand{\edit}{\sigma}
\newcommand{\T}{\theta}
\newcommand{\comp}{;}
\newcommand{\pre}{\prec_P}
\newcommand{\meth}{KSISA}


\newcommand{\MyParagraph}[1]{\textbf{#1}{ }}

\usepackage{vmargin}
\setpapersize{USletter}
\setmarginsrb{1.0in}{1in}{1.0in}{1in}%
           {0pt}{0mm}{0pt}{10mm}
\newcommand{\remove}[1]{}

\usepackage{tweaklist}
\renewcommand{\enumhook}{\setlength{\topsep}{0pt}%
  \setlength{\itemsep}{0pt}}
\renewcommand{\itemhook}{\setlength{\topsep}{0pt}%
  \setlength{\itemsep}{0pt}}
\renewcommand{\descripthook}{\setlength{\topsep}{0pt}%
  \setlength{\itemsep}{0pt}}

\newcommand{\tool}{\textsc{NeuralPPA}\xspace}

\begin{document}

% Collaborative Research: SHF: Small: 



\begin{center}
  {\bf Project Summary: SHF: Small: Neural Program Analysis Infrastructure and Its Applications}
\end{center}
\vspace{-.1in}


%{\bf Overview.}
Analyzing code snippets is not straightforward as they are often
incomplete, un-parseable, contain declaration/reference ambiguity, and
may be interspersed between user comments. Such an infrastructure must
include fundamental supports/services at the structural and semantic
levels, thus enabling the program analysis techniques to be built
upon. The basic infrastructure for partial program analysis, i.e., for
analyzing incomplete code is not yet available. No such infrastructure
has lead to several limitations. For example, it is impossible to
utilize vulnerability detection tools to find vulnerabilities in code
snippets because they rely on program representations that cannot be
built for the incomplete code. In addition to vulnerability detection,
such an infrastructure is also beneficial to other software
engineering (SE) tasks that can tolerate a low level of errors and
imprecision in building program representations.

To this effect, we set out to investigate {\tool}, a {\em \underline{Neural} Network-Based \underline{P}rogram \underline{A}nalysis} infrastructure. We aim to establish {\em a scientific foundation, novel methodologies, frameworks, models, and algorithmic solutions for neural program analysis}. We address two major issues in Program Analysis:

(1) {\bf Enabling analysis of incomplete code fragments}, i.e.,
partial program analysis;

(2) {\bf Empowering existing PA tools by making them more sound and
  complete}. {\tool} will allow the construction of efficient program
analysis techniques for (partial) code on which downstream software
engineering applications can be built.

\noindent {\bf Intellectual Merits.}  In this work, our key philosophy
is that {\em the analysis of partial code can be learned from the
  analysis of entire programs in the wealth of information from
  ultra-large-scale, open-source software repositories}.  In {\tool},
we propose the following thrusts of research. First, the basic
infrastructure in {\tool} is the neural structural analysis component.
It learns from the syntactic structures of the complete code in the
training dataset collected from large-scale code repositories, to
derive the abstract syntax tree (AST) that best represents the
syntactic structure. Next, this component is to tag the code tokens
with the types of the syntactic units.  Second, the basis components
for several analysis techniques on the semantics of the program
include 1) the identification of the APIs of the external libraries in
the external references in the partial code, 2) the inference of the
type information for the entities in the partial code, and 3) the
inference of the program dependencies among the statements in the
partial code. Third, we aim to explore the novel area in AI named
neuro-symbolic learning, which seeks to combine traditional
rules-based AI approaches with modern deep learning
techniques. Fourth, symbolic execution is a means of analyzing a
program to determine what inputs cause each part of a program to
execute. Symbolic execution performs executing a program abstractly,
so that one abstract execution covers multiple possible inputs, which
are assumed to have symbolic values. Our last thrust of research is
aimed to evaluate our basic partial program analysis infrastructure in
a few applications. We choose the following software engineering
applications: 1) software vulnerability detection for code snippets,
2) fault localization, and 3) code completion.

\noindent {\bf Broader Impacts.}  (1) {\tool} will be {\em
  transformative and directly benefit to our society}, leading to
increasing developersâ€™ productivity and software quality. It enables
efficient \textit{impact analysis} during the integration of code
snippets by identifying the potential consequences of the change. It
enables \textit{partial program slicing} and \emph{empowers} dynamic
analysis by identifying additional path conditions (neural
constraints) for the SAT/SMT solvers which helps in exploring the
right subset of the symbolic state space.
%
Our validation involves students and professionals, promoting teaching
and learning of software qualities that have wide impacts in industry
and academic communities. (2) Our results will {\em foster research
  activities} in related fields such as deep learning and software
reliability. This project will produce theoretical concepts and
techniques that are novel even in deep learning, e.g., novel neural
networks for code. (3) The research will enhance the infrastructure
for teaching and research by providing tools and data sets for use by
students and practitioners, and for enhancement by other
researchers. We will provide related learning modules for students.

\noindent {\bf Keywords:} Deep Learning, Program Analysis, Partial Program Analysis.


%Finding and fixing bugs are vital to produce reliable and high-quality
%software. Failing to fix a bug could result in severe consequences.
%In 1996, the Ariane 5 rocket, the European Space Agency's \$1 billion,
%was destroyed less than a minute after launch, due to a bug in the
%on-board guidance computer program. A study commissioned by the US
%Department of Commerce' National Institute of Standards and Technology
%(NIST) concluded that software bugs, or errors, are so prevalent and
%so detrimental that they cost the US economy an estimated \$59 billion
%annually, or about 0.6 percent of the gross domestic product.

%\textbf{- We could learn to fix a bug from similar ones}.

%There is no known, established straightforward methodology for bug
%fixing. Thus, like other problem-solving tasks, developers generally
%base on their own knowledge and experience with the systems, or learn
%from the others to do this task. In other words, they could
%effectively find and fix a bug by consulting the similar bugs and
%fixes to the one they are dealing with. However, currently, such
%learning is still ad-hoc, manually, and un-systematically. For
%example, when facing a bug, people could go to a forum to post a
%question and wait for the help from the others. They could also
%compile the reference manuals, as well as reports, tutorials,
%discussions to find a suitable fix.

%If we have automatic tool support that captures knowledge about bugs
%and fixes and leverages it in fixing the recurring/similar bugs, we
%could reduce the cost for software development.

%\textbf{- Current approaches supporting fixing recurring bugs are still limited}.

%However, current tool support that captures knowledge of known fixes
%and leverage it in fixing/patching in similar bugs are still
%limited. Some automatic tools are limited in recognize and synchronize
%the fixes, etc. For example, there is no any extensive research that
%discover the cause, the nature, and the characteristics of recurring
%bugs and fixes? That is, why are they recurring? How popular they are?
%How they are alike? What features help us recognize their
%recurrence/similarity? 1. How could we identify the API-related code
%peers within and across software projects and assess their popularity?
%. Does the limited support to their co-evolution affect the quality
%of the software system and the effectiveness of the development
%process? 3. How could we synchronize their changes, i.e. given the
%fix/patch of a peer, recommend developers the fixes/patches for its
%other peers?

\end{document} 
