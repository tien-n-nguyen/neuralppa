\section{Thrust 3. Neural-Symbolic Execution Infrastructure}
\label{sec:thrust3}

%\subsection{Planned Work on Neural Network-Based Approaches to Symbolic Execution}

\begin{wrapfigure}{l}{0.45\textwidth}
\begin{lstlisting}[basicstyle=\scriptsize\sffamily, stepnumber=1, numbers=left, numbersep=-6pt, framexleftmargin=0mm, framexrightmargin=0mm, language=Java, emph ={a, b, c}]
    int classify(int a, int b, int c) {
        if (a<=0 || b<=0 || c <= 0) return 4;
        int type=0;
        if (a==b) type+=1;
        if (a==c) type+=2;
        if (b==c) type+=3;
        if (type==0) {
            if (a+b<=c || b+c<=a || a+c>=b) type=4;
            else type=1;
            return type;
        }
        if (type>3) type=3;
        else if (type==1 && a+b>c) type=2;
        else if (type==2 && a+c>b) type=2;
        else if (type==3 && b+c>a) type=2;
        else type=4;
        return type;
    }
\end{lstlisting}
\vspace{-0.1in}
\caption{Solution for Myers' triangle problem~\cite{10.1145/2338965.2336773}}
\label{se-example}
\end{wrapfigure}

Consider the code example in Figure~\ref{se-example} which presents a solution to the Myers' triangle problem~\cite{Myers.2012}. Here, the method \code{classify} reads the parameters \code{a}, \code{b}, and \code{c} as the side lengths of a triangle to return \code{1}, \code{2}, \code{3} or \code{4}, each representing whether the triangle is \textit{scalene}, \textit{isoceles}, \textit{equilateral}, or \textit{illegal} (i.e., do not satisfy the triangle properties). If we regard Java's full integer range for the variables \code{a}, \code{b}, and \code{c}, this program is buggy in that it can cause an arithmetic flow error from the additions in the code (i.e., \code{a+b}, \code{b+c} or \code{a+c} on lines 8, 13-15). Consequently, the method will always conclude that the triangle is illegal. 

In general, it is challenging to realize this bug. Under the assumption that the inputs are uniformly distributed within their domains, Geldenhuys et al.~\cite{10.1145/2338965.2336773} proposed {\em probabilistic symbolic execution} to address this issue. The underlying theme of this approach is to assign probabilities to program paths by counting the number of solutions to a path condition (i.e., model counting). For example, if \code{a, b, c} $\in [-1000, 1000]$, the probability that the method \code{classify} returns \textit{scalene}, \textit{isoceles}, \textit{equilateral}, and \textit{illegal} for a set of inputs is $2.07 \times 10^{-2}$, $2.80 \times 10^{-4}$, $1.25 \times 10^{-7}$, and $9.79 \times 10^{-1}$ respectively. By enhancing the semantics of a program with such probabilities, they claim that model counting is useful in obtaining coverage information and bug finding.


%Symbolic execution deals with applying constraints over the inputs to determine the execution paths in a program. The composition of these input spaces results in many possible paths an execution might cover. In \cite{10.1145/2338965.2336773}, Geldenhuys {\em et al}. proposed {\em probabilistic symbolic execution}, which counts the number of solutions to a path condition ({\em i.e.}, model counting), thus enabling the assignment of probabilities to program paths. However, this is a byproduct of the assumptions on the uniform distribution of the inputs within their domains. By enhancing the semantics of a program with such probabilities, model counting is useful in obtaining coverage information and bug finding/localization.


However, such a count-based technique is limited. In contrast, as a part of the neuro-symbolic execution infrastructure, we plan to leverage neural networks for determining all possible program paths with their occurrence probabilities. The basis of this work is {\em execution-trace modeling} which, given an input and a program, determines the execution trace of the program. In our preliminary work on neural program dependence analysis, we observed that our model is able to learn the sense of an execution trace on different attention heads. Thus motivated, we plan to utilize a similar framework composed with the latent test input representations to predict the corresponding execution trace. We can also facilitate {\em code coverage modeling} with the knowledge of how a part of the program is executed as the domain of the input variables changes. 

Next, we will extend this work to the model counting problem, where, we will predict the number of all possible execution traces for a given program, and the likelihood of their occurrence. To enable this problem setting, we will use a trainable threshold parameter, which will be updated after each iteration in accordance with the criteria defined in the loss function (similar to any other parameters of the model). We can then re-adjust the probabilities corresponding to all program paths that breach this threshold parameter to sum to one, thus establishing the infrastructure for neural network-based probabilistic symbolic execution.  
